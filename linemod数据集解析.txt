1.linemod数据集下的data
每个标签下共有:
(1)depth(目录):深度图
(2)mask(目录):目标物体的掩码,为标准的分割结果
(3)rgb(目录):保存为RGB图像
(4)gt.yml(文件):保存了拍摄每张图片时，其对应的旋转矩阵和偏移矩阵，以及目标物体的标准box,和该图像中目标物体所属于的类别
(5)info.yml(文件):拍摄每张图片,对应的摄像头的内参，以及深度缩放的比例
2.segnet_results是通过对目标物体进行语义分割得到的结果。在训练模型的时候，使用标准的数据训练模型，训练和验证的时候都使用标准的mask，作为
分割的标签，在测试的时候，希望接近实际场景，对分割出来的目标进行姿态预测。所以segnet_results保存的是语义分割网络分割出来的图片。
3.models表示模型，用点云数据表示
(1).ply文件:每个ply文件其中的点云信息都是以第一张图片为参考面的，有了这个参考面的点云数据，就能根据其他的拍摄照片时的摄像头参数(旋转和偏移矩阵)计算出
其他的视觉对应的点云数据。
总体上，对第一张图片进行3D点云数据的建模，建模之后，对着目标拍摄到的图片可根据摄像头的参数，结合第一帧图片的3D点云数据计算出对应的3D点
云数据。
(2)models_info.yml文件:保存的是每个目标点云模型的半径,x,y,x轴的起始值和大小范围。